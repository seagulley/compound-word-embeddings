{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretraining the IMDb model for finetuning on the compound word prediction task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kalliehuynh/miniforge3/envs/stenv/lib/python3.8/site-packages/jax/_src/lib/__init__.py:34: UserWarning: JAX on Mac ARM machines is experimental and minimally tested. Please see https://github.com/google/jax/issues/5501 in the event of problems.\n",
      "  warnings.warn(\"JAX on Mac ARM machines is experimental and minimally tested. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kalliehuynh/miniforge3/envs/stenv/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import tflearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tflearn.data_utils import to_categorical, pad_sequences\n",
    "from tflearn.datasets import imdb\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.embedding_ops import embedding\n",
    "from tflearn.layers.recurrent import bidirectional_rnn, BasicLSTMCell\n",
    "from tflearn.layers.estimator import regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "tf.set_random_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_neg = pd.read_csv('test_neg.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos = pd.read_csv('test_pos.csv')\n",
    "train_neg = pd.read_csv('train_neg.csv')\n",
    "train_pos = pd.read_csv('train_pos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [train_neg, train_pos]\n",
    "train = pd.concat(train)\n",
    "train = train.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [test_neg, test_pos]\n",
    "test = pd.concat(test)\n",
    "test = test.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.sample(frac=1).reset_index(drop=True)\n",
    "train = train.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = [[np.array(json.loads(embedding), dtype='float32') for embedding in train.iloc[i, :100]] for i in range(350)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = [int(i) for i in train.iloc[:350, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 word_00  \\\n",
      "0      [[-0.167062942089733, 0.1052116373842762, 0.17...   \n",
      "1      [[0.1040415732190503, 0.1000910442357138, 0.24...   \n",
      "2      [[-0.167062942089733, 0.1052116373842762, 0.17...   \n",
      "3      [[0.2583571057403827, 0.2545965502061464, 0.11...   \n",
      "4      [[-0.3279381770666981, 0.1269941372943537, 0.1...   \n",
      "...                                                  ...   \n",
      "24995  [[0.0597157799774428, 0.2024493176656686, 0.19...   \n",
      "24996  [[-0.167062942089733, 0.1052116373842762, 0.17...   \n",
      "24997  [[0.2583571057403827, 0.2545965502061464, 0.11...   \n",
      "24998  [[0.2583571057403827, 0.2545965502061464, 0.11...   \n",
      "24999  [[-0.167062942089733, 0.1052116373842762, 0.17...   \n",
      "\n",
      "                                                 word_01  \\\n",
      "0      [[0.4452949018238277, 0.381905943230363, 0.472...   \n",
      "1      [[-0.1099969348851542, -0.0353920206883006, 0....   \n",
      "2      [[0.4749093903272134, 0.3018275609945992, 0.17...   \n",
      "3      [[0.1430436907671176, 0.3510640850110125, 0.08...   \n",
      "4      [[0.1191896982285018, 0.0749506533483837, 0.14...   \n",
      "...                                                  ...   \n",
      "24995  [[0.3122799477909785, 0.2394169733026231, 0.19...   \n",
      "24996  [[0.4749093903272134, 0.3018275609945992, 0.17...   \n",
      "24997  [[0.2732062506373802, 0.560301481941315, 0.052...   \n",
      "24998  [[-0.1079154688430455, 0.2588262365999713, 0.0...   \n",
      "24999  [[-0.2113139942828394, 0.1277031370499133, 0.1...   \n",
      "\n",
      "                                                 word_02  \\\n",
      "0      [[-0.1488772814275358, 0.3944548857417299, 0.2...   \n",
      "1      [[0.0378606621842307, 0.3620429896066244, 0.15...   \n",
      "2      [[-0.2113139942828394, 0.1277031370499133, 0.1...   \n",
      "3      [[-0.0290359885860495, 0.7225627029127366, -0....   \n",
      "4      [[-0.0630364113628468, 0.3670709442560383, 0.1...   \n",
      "...                                                  ...   \n",
      "24995  [[-0.1889733270110498, 0.3130670629789491, 0.0...   \n",
      "24996  [[0.4977290484322996, 0.2271753266683387, 0.15...   \n",
      "24997  [[-0.3279381770666981, 0.1269941372943537, 0.1...   \n",
      "24998  [[-0.0110179469419692, 0.0969679173034671, 0.0...   \n",
      "24999  [[0.4375451621140112, 0.212242185968568, 0.374...   \n",
      "\n",
      "                                                 word_03  \\\n",
      "0      [[0.1521633196974854, 0.1602272452148427, 0.05...   \n",
      "1      [[0.2235925659480276, 0.2294976987689243, 0.43...   \n",
      "2      [[0.1729216259321031, 0.4594052343862621, 0.02...   \n",
      "3      [[-0.1126883969633084, 0.4886252697478084, 0.1...   \n",
      "4      [[-0.1978754622450163, 0.0551358270909763, -0....   \n",
      "...                                                  ...   \n",
      "24995  [[0.0416569498522746, 0.0954864324590063, 0.45...   \n",
      "24996  [[-0.1978754622450163, 0.0551358270909763, -0....   \n",
      "24997  [[0.2261592237168907, 1.0715490928745948, 0.01...   \n",
      "24998  [[-0.5451320058038759, 0.3862398421064598, -0....   \n",
      "24999  [[-0.2565506398727492, 0.0734490589720875, 0.1...   \n",
      "\n",
      "                                                 word_04  \\\n",
      "0      [[0.0794640891422153, 0.4377981108416686, 0.53...   \n",
      "1      [[-0.0137867294388, 0.0581054185553036, 0.1082...   \n",
      "2      [[-0.2558250201255586, 0.1627932802989327, 0.0...   \n",
      "3      [[-0.1079163565166097, 0.0772231141860003, 0.0...   \n",
      "4      [[-0.3279381770666981, 0.1269941372943537, 0.1...   \n",
      "...                                                  ...   \n",
      "24995  [[0.227659708529037, -0.0493468186943887, 0.25...   \n",
      "24996  [[0.257144630919288, 0.2981291199949034, 0.140...   \n",
      "24997  [[-0.4800373133650642, 0.4042496581166335, -0....   \n",
      "24998  [[0.0504831736628445, 0.3617829843777022, -0.0...   \n",
      "24999  [[-0.5451320058038759, 0.3862398421064598, -0....   \n",
      "\n",
      "                                                 word_05  \\\n",
      "0      [[-0.1126883969633084, 0.4886252697478084, 0.1...   \n",
      "1      [[0.2668460544772181, -0.3258719723701744, 0.3...   \n",
      "2      [[0.3856966033462121, 0.1228495086332605, 0.03...   \n",
      "3      [[0.3352500308402227, 0.550451827880334, -0.09...   \n",
      "4      [[0.0692139036525291, 0.2474523745653793, -0.0...   \n",
      "...                                                  ...   \n",
      "24995  [[0.4335529827572589, 0.1158244679531037, 0.52...   \n",
      "24996  [[0.0909611793731013, 0.2725163307397039, 0.23...   \n",
      "24997  [[-0.2086447830417357, 0.3713295005548119, 0.1...   \n",
      "24998  [[-0.0657058512660115, 0.088468108112704, 0.19...   \n",
      "24999  [[-0.1978754622450163, 0.0551358270909763, -0....   \n",
      "\n",
      "                                                 word_06  \\\n",
      "0      [[-0.2558250201255586, 0.1627932802989327, 0.0...   \n",
      "1      [[-0.1978754622450163, 0.0551358270909763, -0....   \n",
      "2      [[-0.5451320058038759, 0.3862398421064598, -0....   \n",
      "3      [[-0.4800373133650642, 0.4042496581166335, -0....   \n",
      "4      [[-0.4800373133650642, 0.4042496581166335, -0....   \n",
      "...                                                  ...   \n",
      "24995  [[0.227659708529037, -0.0493468186943887, 0.25...   \n",
      "24996  [[-0.0077896580534995, 0.3056072061401269, -0....   \n",
      "24997  [[-0.2558250201255586, 0.1627932802989327, 0.0...   \n",
      "24998  [[-0.167062942089733, 0.1052116373842762, 0.17...   \n",
      "24999  [[-0.3926924567564325, 0.1494864339334805, -0....   \n",
      "\n",
      "                                                 word_07  \\\n",
      "0      [[-0.1084624694568285, -0.0538579346753361, 0....   \n",
      "1      [[0.3280456418719983, 0.0746137818109387, 0.11...   \n",
      "2      [[-0.3659982582861063, 0.2881394152530195, 0.0...   \n",
      "3      [[-0.1978754622450163, 0.0551358270909763, -0....   \n",
      "4      [[-0.1956348292460063, -0.0374000062353819, 0....   \n",
      "...                                                  ...   \n",
      "24995  [[0.4335529827572589, 0.1158244679531037, 0.52...   \n",
      "24996  [[-0.1488772814275358, 0.3944548857417299, 0.2...   \n",
      "24997  [[0.0917854661044223, 0.3323281375982265, 0.08...   \n",
      "24998  [[0.4749093903272134, 0.3018275609945992, 0.17...   \n",
      "24999  [[0.5804862114860836, 0.4732138664883821, 0.21...   \n",
      "\n",
      "                                                 word_08  \\\n",
      "0      [[-0.4800373133650642, 0.4042496581166335, -0....   \n",
      "1      [[0.0378606621842307, 0.3620429896066244, 0.15...   \n",
      "2      [[0.1812985290745026, 0.4190344111611503, 0.24...   \n",
      "3      [[0.2314956416159368, 0.0430213737403019, 0.00...   \n",
      "4      [[0.0214489136333439, 0.2751210473982294, -0.0...   \n",
      "...                                                  ...   \n",
      "24995  [[0.1259409784487029, 0.2346443340948636, 0.06...   \n",
      "24996  [[0.012350808447971, 0.3623317966690126, -0.05...   \n",
      "24997  [[-0.5451320058038759, 0.3862398421064598, -0....   \n",
      "24998  [[-0.4800373133650642, 0.4042496581166335, -0....   \n",
      "24999  [[0.2583571057403827, 0.2545965502061464, 0.11...   \n",
      "\n",
      "                                                 word_09  ...  \\\n",
      "0      [[-0.2558250201255586, 0.1627932802989327, 0.0...  ...   \n",
      "1      [[0.2923794196947023, -0.0705273307223239, 0.3...  ...   \n",
      "2      [[0.4779436671087492, 0.0036941954644642, 0.20...  ...   \n",
      "3      [[0.1249272297426129, -0.2259526916461964, 0.3...  ...   \n",
      "4      [[0.1228847900072753, 0.4539739106120552, 0.22...  ...   \n",
      "...                                                  ...  ...   \n",
      "24995  [[0.2400868017830051, 0.1372224186340863, 0.34...  ...   \n",
      "24996  [[0.4749093903272134, 0.3018275609945992, 0.17...  ...   \n",
      "24997  [[0.4244330912405193, 0.5229387445437231, 0.11...  ...   \n",
      "24998  [[0.2583571057403827, 0.2545965502061464, 0.11...  ...   \n",
      "24999  [[0.3825011735954288, 0.4898536196659852, 0.03...  ...   \n",
      "\n",
      "                                                 word_91  \\\n",
      "0      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "1      [[0.1743008596805099, 0.0925501360739593, 0.38...   \n",
      "2      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "3      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "4      [[0.2342634573436398, 0.0147931380778834, 0.02...   \n",
      "...                                                  ...   \n",
      "24995  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "24996  [[-0.1978754622450163, 0.0551358270909763, -0....   \n",
      "24997  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "24998  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "24999  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "\n",
      "                                                 word_92  \\\n",
      "0      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "1      [[0.0214489136333439, 0.2751210473982294, -0.0...   \n",
      "2      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "3      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "4      [[0.2989031895266073, 0.005947649631805, 0.604...   \n",
      "...                                                  ...   \n",
      "24995  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "24996  [[-0.1430729692744307, 0.1158352082474559, 0.2...   \n",
      "24997  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "24998  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "24999  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "\n",
      "                                                 word_93  \\\n",
      "0      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "1      [[-0.1978754622450163, 0.0551358270909763, -0....   \n",
      "2      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "3      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "4      [[0.0378606621842307, 0.3620429896066244, 0.15...   \n",
      "...                                                  ...   \n",
      "24995  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "24996  [[-0.2113139942828394, 0.1277031370499133, 0.1...   \n",
      "24997  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "24998  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "24999  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "\n",
      "                                                 word_94  \\\n",
      "0      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "1      [[0.1019849876547244, 0.2987376885439868, 0.31...   \n",
      "2      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "3      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "4      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "...                                                  ...   \n",
      "24995  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "24996  [[-0.2558250201255586, 0.1627932802989327, 0.0...   \n",
      "24997  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "24998  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "24999  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "\n",
      "                                                 word_95  \\\n",
      "0      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "1      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "2      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "3      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "4      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "...                                                  ...   \n",
      "24995  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "24996  [[0.2243666730446648, 0.629104736586239, 0.035...   \n",
      "24997  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "24998  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "24999  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "\n",
      "                                                 word_96  \\\n",
      "0      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "1      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "2      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "3      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "4      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "...                                                  ...   \n",
      "24995  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "24996  [[-0.1488772814275358, 0.3944548857417299, 0.2...   \n",
      "24997  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "24998  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "24999  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "\n",
      "                                                 word_97  \\\n",
      "0      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "1      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "2      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "3      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "4      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "...                                                  ...   \n",
      "24995  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "24996  [[-0.3516360527497433, 0.5314076994649053, 0.1...   \n",
      "24997  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "24998  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "24999  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "\n",
      "                                                 word_98  \\\n",
      "0      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "1      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "2      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "3      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "4      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "...                                                  ...   \n",
      "24995  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "24996  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "24997  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "24998  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "24999  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "\n",
      "                                                 word_99 positive  \n",
      "0      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...        1  \n",
      "1      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...        0  \n",
      "2      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...        1  \n",
      "3      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...        1  \n",
      "4      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...        0  \n",
      "...                                                  ...      ...  \n",
      "24995  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...        0  \n",
      "24996  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...        1  \n",
      "24997  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...        0  \n",
      "24998  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...        0  \n",
      "24999  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...        0  \n",
      "\n",
      "[25000 rows x 101 columns]\n"
     ]
    }
   ],
   "source": [
    "testX = [[np.array(json.loads(embedding), dtype='float32') for embedding in test.iloc[i, :100]] for i in range(175)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "testY = [int(i) for i in test.iloc[:175, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/kalliehuynh/compound-word-embeddings/IMDB_BiLSTM.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kalliehuynh/compound-word-embeddings/IMDB_BiLSTM.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainX \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(trainX)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kalliehuynh/compound-word-embeddings/IMDB_BiLSTM.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m trainX \u001b[39m=\u001b[39m trainX\u001b[39m.\u001b[39mreshape(\u001b[39m350\u001b[39m, \u001b[39m100\u001b[39m, \u001b[39m768\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kalliehuynh/compound-word-embeddings/IMDB_BiLSTM.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m trainY \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(trainY)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainX' is not defined"
     ]
    }
   ],
   "source": [
    "trainX = np.array(trainX)\n",
    "trainX = trainX.reshape(350, 100, 768)\n",
    "trainY = np.array(trainY)\n",
    "trainY = trainY.reshape(350, 1)\n",
    "testX = np.array(testX)\n",
    "testX = testX.reshape(175, 100, 768)\n",
    "testY = np.array(testY)\n",
    "testY = testY.reshape(175, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = to_categorical(trainY)\n",
    "testY = to_categorical(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = trainY.reshape((350, 2))\n",
    "testY = testY.reshape((175, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kalliehuynh/miniforge3/envs/stenv/lib/python3.8/site-packages/tflearn/layers/recurrent.py:67: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /Users/kalliehuynh/miniforge3/envs/stenv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1082: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/kalliehuynh/miniforge3/envs/stenv/lib/python3.8/site-packages/tflearn/initializations.py:164: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "net = input_data(shape=[None, 100, 768])\n",
    "net = tflearn.lstm(net, 128, dropout=0.8)\n",
    "net = tflearn.fully_connected(net, 2, activation='softmax')\n",
    "net = tflearn.regression(net, optimizer='adam', learning_rate=0.0005,\n",
    "                         loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-09 22:32:22.600855: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "model = tflearn.DNN(net, tensorboard_verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 5191  | total loss: \u001b[1m\u001b[32m0.02992\u001b[0m\u001b[0m | time: 9.518s\n",
      "| Adam | epoch: 101 | loss: 0.02992 - acc: 0.9919 -- iter: 348/350\n",
      "Training Step: 5192  | total loss: \u001b[1m\u001b[32m0.02705\u001b[0m\u001b[0m | time: 10.699s\n",
      "| Adam | epoch: 101 | loss: 0.02705 - acc: 0.9927 | val_loss: 2.74971 - val_acc: 0.5600 -- iter: 350/350\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model.fit(trainX, trainY, validation_set=(testX, testY), show_metric=True, n_epoch=101, batch_size=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('stenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c9c1e931f97bf0988d4b0e08b56fbd4208c7bcd528771344c324ad3f2e1513e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
